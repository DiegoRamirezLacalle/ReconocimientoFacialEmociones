# Reconocimiento de Expresiones Faciales con CNN y Vision Transformer (ViT)

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-orange.svg)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.111+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com/)

Sistema de reconocimiento de expresiones faciales que combina dos enfoques de aprendizaje profundo: **CNN entrenada desde cero** y **Vision Transformer (ViT) con fine-tuning**. Incluye API REST con FastAPI, interfaz web interactiva y despliegue completo con Docker.

**Autores:** Diego RamÃ­rez & Jorge Clausen  
**Fecha:** Noviembre 2025

---

## Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
  - [OpciÃ³n 1: Docker (Recomendado)](#opciÃ³n-1-docker-recomendado)
  - [OpciÃ³n 2: InstalaciÃ³n Local](#opciÃ³n-2-instalaciÃ³n-local)
- [Uso](#-uso)
- [API Endpoints](#-api-endpoints)
- [Modelos](#-modelos)
- [Desarrollo](#-desarrollo)
- [Arquitectura](#-arquitectura)

---

## CaracterÃ­sticas

- **Dos modelos de Deep Learning:**
  - CNN personalizada entrenada desde cero (7 clases de emociones)
  - Vision Transformer (ViT) con fine-tuning desde modelo preentrenado
- **API REST con FastAPI:**
  - PredicciÃ³n en tiempo real sobre imÃ¡genes
  - Cambio dinÃ¡mico entre modelos CNN/ViT
  - Retorna probabilidades para todas las emociones
- **Interfaz web interactiva:**
  - Captura desde webcam en tiempo real
  - Upload de imÃ¡genes
  - VisualizaciÃ³n de probabilidades con grÃ¡ficos
- **ContenerizaciÃ³n completa:**
  - Docker Compose orquesta backend + frontend
  - Reproducibilidad total del entorno
  - Listo para producciÃ³n

---

## TecnologÃ­as

### Backend
- **Python 3.10**
- **PyTorch 2.1** (CUDA 12.1)
- **FastAPI** para API REST
- **Uvicorn** como servidor ASGI
- **Transformers** (HuggingFace) para ViT
- **timm** para modelos de visiÃ³n
- **OpenCV**, **MediaPipe**, **MTCNN** para preprocesamiento

### Frontend
- HTML5, CSS3, JavaScript vanilla
- WebRTC para captura de webcam

### DevOps
- **Docker** y **Docker Compose**
- **Nginx** como proxy reverso y servidor estÃ¡tico

---

## Estructura del Proyecto

```
ReconocimientoFacialEmociones/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                    # API (estructura alternativa, vacÃ­a)
â”‚   â”œâ”€â”€ backen/                 # Backend principal FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py            # Entrypoint de la API
â”‚   â”‚   â”œâ”€â”€ inference.py       # Clase EmotionPredictor
â”‚   â”‚   â””â”€â”€ index.html         # Frontend integrado
â”‚   â””â”€â”€ fer/                    # MÃ³dulo de Deep Learning
â”‚       â”œâ”€â”€ models/            # Arquitecturas CNN/ViT
â”‚       â”œâ”€â”€ train/             # Scripts de entrenamiento + checkpoints (.pt)
â”‚       â”œâ”€â”€ eval/              # EvaluaciÃ³n y mÃ©tricas
â”‚       â””â”€â”€ utils/             # Utilidades
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                   # Datasets (FER-2013, AffectNet)
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ val/
â”‚       â””â”€â”€ test/
â”œâ”€â”€ configs/                   # Configuraciones YAML
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml     # OrquestaciÃ³n de servicios
â”‚   â””â”€â”€ nginx.conf             # Config Nginx
â”œâ”€â”€ notebooks/                 # Jupyter notebooks de exploraciÃ³n
â”œâ”€â”€ Dockerfile                 # Imagen Docker del backend
â”œâ”€â”€ pyproject.toml             # Dependencias del proyecto
â””â”€â”€ README.md                  # Este archivo
```

---

---

## OrganizaciÃ³n de carpetas

El proyecto sigue una estructura modular que separa claramente **backend**, **modelos**, **datos**, **entrenamiento** y **despliegue**.

###  `src/backen/`
Contiene la aplicaciÃ³n principal de FastAPI:
- `main.py`: Entrypoint de la API REST
- `inference.py`: LÃ³gica de carga de modelos y predicciÃ³n
- `index.html`: Interfaz web integrada (frontend ligero)

---

###  `src/fer/`
MÃ³dulo de Deep Learning (Facial Emotion Recognition):

#### ğŸ”¸ `models/`
- DefiniciÃ³n de arquitecturas CNN y ViT
- Clases PyTorch (`nn.Module`)

#### ğŸ”¸ `train/`
- Scripts de entrenamiento
- Checkpoints finales de los modelos (`.pt`)
- **Estos pesos son los que se cargan en producciÃ³n**

#### ğŸ”¸ `eval/`
- EvaluaciÃ³n de modelos
- MÃ©tricas (accuracy, confusion matrix, etc.)

#### ğŸ”¸ `utils/`
- Funciones auxiliares de preprocesado
- NormalizaciÃ³n, transformaciones y helpers

---

###  `data/`
Contiene los datasets **solo para entrenamiento** (no incluidos en Docker):

```text
data/
â””â”€â”€ raw/
    â”œâ”€â”€ fer2013/
    â”‚   â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ val/
    â”‚   â””â”€â”€ test/
    â””â”€â”€ affectnet/
        â”œâ”€â”€ train/
        â”œâ”€â”€ val/
        â””â”€â”€ test/


##  Requisitos Previos

### Para Docker (Recomendado)
- [Docker](https://www.docker.com/get-started) >= 20.10
- [Docker Compose](https://docs.docker.com/compose/install/) >= 2.0
- (Opcional) GPU NVIDIA + [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) para inferencia con CUDA

### Para InstalaciÃ³n Local
- Python 3.10+
- CUDA 12.1 (opcional, para GPU)
- Git

---

##  InstalaciÃ³n

### OpciÃ³n 1: Docker (Recomendado)

**1. Clonar el repositorio:**
```bash
git clone https://github.com/tu-usuario/ReconocimientoFacialEmociones.git
cd ReconocimientoFacialEmociones
```

**2. Construir y lanzar los servicios:**
```bash
cd docker
docker compose up --build
```

**3. Acceder a la aplicaciÃ³n:**
- **Frontend:** http://localhost
- **API (docs):** http://localhost/api/docs
- **API directa:** http://localhost:8000

**Para detener:**
```bash
docker compose down
```

---

### OpciÃ³n 2: InstalaciÃ³n Local

**1. Clonar el repositorio:**
```bash
git clone https://github.com/tu-usuario/ReconocimientoFacialEmociones.git
cd ReconocimientoFacialEmociones
```

**2. Crear entorno virtual:**
```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

**3. Instalar PyTorch con CUDA (o CPU):**
```bash
# CUDA 12.1
pip install --index-url https://download.pytorch.org/whl/cu121 torch==2.1.0 torchvision==0.16.0

# O solo CPU
pip install torch==2.1.0 torchvision==0.16.0
```

**4. Instalar dependencias:**
```bash
pip install -e .
```

**5. Ejecutar el servidor:**
```bash
uvicorn src.backen.main:app --host 0.0.0.0 --port 8000 --reload
```

**6. Abrir el frontend:**
- Navega a http://localhost:8000
- O abre directamente `src/backen/index.html` en el navegador

---

##  Uso

### Interfaz Web

1. **Webcam en tiempo real:**
   - Click en "Activar CÃ¡mara"
   - Presiona "Capturar y Predecir"
   - Ve las probabilidades de cada emociÃ³n en tiempo real

2. **Subir imagen:**
   - Click en "Subir Imagen"
   - Selecciona una foto con rostro
   - Ve la predicciÃ³n instantÃ¡nea

3. **Cambiar modelo:**
   - Botones "CNN" / "ViT" para alternar entre modelos
   - Observa diferencias en predicciones

### LÃ­nea de Comandos (curl)

```bash
# Predecir emociÃ³n en una imagen
curl -X POST "http://localhost:8000/predict" \
  -F "file=@/path/to/image.jpg"

# Cambiar a modelo ViT
curl -X POST "http://localhost:8000/switch-model/vit"

# Cambiar a modelo CNN
curl -X POST "http://localhost:8000/switch-model/cnn"
```

### Python

```python
import requests

# Predecir emociÃ³n
with open("imagen.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8000/predict",
        files={"file": f}
    )
    print(response.json())
    # {
    #   "dominant_emotion": "Happy",
    #   "predictions": {
    #     "Happy": 0.85,
    #     "Neutral": 0.10,
    #     "Surprise": 0.03,
    #     ...
    #   },
    #   "model": "cnn"
    # }
```

---

##  API Endpoints

### `GET /`
Retorna la interfaz web HTML.

**Response:** HTML frontend

---

### `POST /predict`
Predice la emociÃ³n en una imagen.

**Request:**
- `Content-Type: multipart/form-data`
- `file`: Archivo de imagen (JPG, PNG, etc.)

**Response:**
```json
{
  "dominant_emotion": "Happy",
  "predictions": {
    "Angry": 0.02,
    "Disgust": 0.01,
    "Fear": 0.01,
    "Happy": 0.85,
    "Sad": 0.03,
    "Surprise": 0.05,
    "Neutral": 0.03
  },
  "model": "cnn"
}
```

---

### `POST /switch-model/{model_name}`
Cambia el modelo activo.

**Path Parameters:**
- `model_name`: `"cnn"` o `"vit"`

**Response:**
```json
{
  "msg": "Cambiado a vit",
  "model": "vit"
}
```

---

##  Modelos

### CNN Personalizada
- **Arquitectura:** 4 bloques Conv + BatchNorm + ReLU + MaxPool
- **ParÃ¡metros:** ~68M (68MB checkpoint)
- **Input:** ImÃ¡genes en escala de grises 224Ã—224
- **Output:** 7 clases de emociones

**Clases:**
1. Angry (Enfado)
2. Disgust (Asco)
3. Fear (Miedo)
4. Happy (Feliz)
5. Sad (Triste)
6. Surprise (Sorpresa)
7. Neutral (Neutral)

### Vision Transformer (ViT)
- **Base:** `mo-thecreator/vit-Facial-Expression-Recognition`
- **Fine-tuning:** Adaptado a 7 clases con dataset combinado
- **ParÃ¡metros:** ~343M (343MB checkpoint)
- **Input:** ImÃ¡genes RGB 224Ã—224
- **Output:** 7 clases de emociones

**Ventajas ViT vs CNN:**
- Mayor precisiÃ³n en escenarios complejos
- Mejor generalizaciÃ³n
- AtenciÃ³n global sobre la imagen

---
---

##  Datasets utilizados

Para el entrenamiento y evaluaciÃ³n de los modelos de reconocimiento de emociones se han utilizado **datasets pÃºblicos ampliamente empleados en investigaciÃ³n**, descargados directamente de sus fuentes oficiales.

### ğŸ”¹ FER-2013
- **DescripciÃ³n:** Dataset clÃ¡sico para reconocimiento de expresiones faciales en escala de grises.
- **NÃºmero de clases:** 7 emociones
- **ResoluciÃ³n:** 48Ã—48 pÃ­xeles (re-escaladas a 224Ã—224 durante el preprocesado)
- **Formato:** ImÃ¡genes en carpetas por clase

 **Fuente oficial:**
- Kaggle â€“ FER-2013  
  https://www.kaggle.com/datasets/msambare/fer2013

 **Licencia:** Uso acadÃ©mico e investigaciÃ³n.

---

### ğŸ”¹ AffectNet
- **DescripciÃ³n:** Dataset a gran escala de expresiones faciales anotadas manualmente.
- **NÃºmero de clases:** 7 emociones bÃ¡sicas
- **ResoluciÃ³n:** Variable (normalizadas a 224Ã—224)
- **Formato:** ImÃ¡genes RGB

**Fuente oficial:**
- Sitio web oficial de AffectNet  
  http://mohammadmahoor.com/affectnet/


---

### ğŸ”¹ Uso de los datasets en el proyecto
- Los datasets se utilizan **exclusivamente en la fase de entrenamiento y evaluaciÃ³n**
- **No se incluyen dentro del contenedor Docker**
- Durante el despliegue solo se cargan los **pesos entrenados (`.pt`)**

##  Desarrollo

### Ejecutar tests
```bash
pytest tests/ -v
```

### Entrenar modelos

**CNN:**
```bash
python -m fer.train.train_cnn --config configs/train_cnn.yaml
```

**ViT:**
```bash
python -m fer.train.train_vit --config configs/train_vit.yaml
```

### Hot reload en desarrollo
```bash
uvicorn src.backen.main:app --reload --host 0.0.0.0 --port 8000
```

---

##  Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend Web  â”‚  (HTML5 + JS + WebRTC)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nginx Proxy   â”‚  (Puerto 80, opcional)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backendâ”‚  (Puerto 8000)
â”‚   (Uvicorn)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EmotionPredictorâ”‚
â”‚   (PyTorch)     â”‚
â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   CNN    â”‚   â”‚  (68MB)
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   ViT    â”‚   â”‚  (343MB)
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---


##  Autores

- **Diego RamÃ­rez Lacalle** - [GitHub](https://github.com/DiegoRamirezLacalle)
- **Jorge Clausen** - [GitHub](https://github.com/jorge-clausen)

**Universidad de Deusto** - Proyecto Reconocimiento Facial de Emociones  
Noviembre 2025

---



